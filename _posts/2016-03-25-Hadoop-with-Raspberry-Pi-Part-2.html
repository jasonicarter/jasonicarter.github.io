---
layout: post
title:  "How to Hadoop at home with Raspberry Pi — Part 2"
---

<section name="d2a1" class=" section--body"><div class="section-content"><div class="section-inner layoutSingleColumn"><p name="29a9" id="29a9" class="graf--p graf--leading">To summarize what I’m doing and how I got here: A couple of weeks ago I decided to dive into the world of Hadoop from my interest in data engineering and analysis. And what’s the best way to do that? Build a Raspberry Pi Hadoop Cluster, of course!</p><p name="8c18" id="8c18" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">This is not a tutorial.</strong> Think of it more as a journey, there’s no nice step-by-step process here, I’m going to make mistakes, get errors, fix them and try to move on.</p><p name="a354" id="a354" class="graf--p graf-after--p">If you want to follow along, you should probably start with <a href="{{ site.url }}/Hadoop-with-Raspberry-Pi-Part-1" class="markup--anchor markup--p-anchor">Part 1</a> which covers setting up Raspberry and some limited network configurations. In this part of the series, I’ll be installing and configuring Hadoop for a single node installation.</p><ol class="postList"><li name="1de9" id="1de9" class="graf--li graf-after--p"><a href="{{ site.url }}/Hadoop-with-Raspberry-Pi-Part-1" class="markup--anchor markup--li-anchor"><em class="markup--em markup--li-em">Part 1: Setting up Raspberry Pi and network configurations</em></a></li><li name="6795" id="6795" class="graf--li graf-after--li"><a href="{{ site.url }}/Hadoop-with-Raspberry-Pi-Part-2" class="markup--anchor markup--li-anchor"><em class="markup--em markup--li-em">Part 2: Hadoop single node setup, testing and prepping the cluster</em></a></li><li name="3a0b" id="3a0b" class="graf--li graf-after--li"><a href="{{ site.url }}/Hadoop-with-Raspberry-Pi-Part-3" class="markup--anchor markup--li-anchor"><em class="markup--em markup--li-em">Part 3: Hadoop cluster setup, testing and final thoughts</em></a></li></ol><p name="6866" id="6866" class="graf--p graf-after--li">Before I forget and we get too far ahead of ourselves, this is all Hadoop 2 with YARN implementation. Hadoop 2 comes with some significant changes and you can also use Hadoop 2 without using YARN (or something like that) which caused me some headaches. But enough of that, let us begin.</p><h4 name="51eb" id="51eb" class="graf--h4 graf-after--p">Hadoop group, users and SSH…</h4><p name="a804" id="a804" class="graf--p graf-after--h4">is pretty straight forward to setup. I’m simplifying things and only creating one group and user instead of a separate user for HDFS, MapReduce and YARN, which seems to be recommended.</p><pre name="66d7" id="66d7" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Add a group, a user and then add the user to the group</strong></pre><pre name="8f5f" id="8f5f" class="graf--pre graf-after--pre">1. $sudo addgroup hadoop<br>2. $sudo adduser --ingroup hadoop hduser<br>3. $sudo adduser hduser sudo</pre><pre name="f23d" id="f23d" class="graf--pre graf-after--pre">You&#39;ll need to enter a password and other typical user info, I entered a password but just used blanks/default values for everything else</pre><p name="fbef" id="fbef" class="graf--p graf-after--pre">Hadoop requires SSH access to communicate and manage its nodes, i.e. nameNodes, secondaryNameNodes, dataNodes, etc. We’ll be using an empty password/phase because we don’t want to have to enter it every time the nodes talk to each other.</p><pre name="0707" id="0707" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Switch users and create SSH key with no passphrase</strong></pre><pre name="5d49" id="5d49" class="graf--pre graf-after--pre">1. $su hduser<br>2. $mkdir ~/.ssh<br>3. $ssh-keygen -t rsa -P &quot;&quot;<br>4. $cat ~/.ssh/id_rsa.pub &gt; ~/.ssh/authorized_keys</pre><p name="8a7d" id="8a7d" class="graf--p graf-after--pre">Verify that you can make a connection to node1. I’m not using any special ports so this was pretty straight forward for me.</p><pre name="dc29" id="dc29" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">If you are prompted to trust node1 / unknown_host, type yes</strong></pre><pre name="4d19" id="4d19" class="graf--pre graf-after--pre graf--last">1. $su hduser<br>2. $ssh node1<br>3. $exit</pre></div></div></section><section name="c4b6" class=" section--body"><div class="section-divider layoutSingleColumn"><hr class="section-divider"></div><div class="section-content"><div class="section-inner layoutSingleColumn"><h3 name="97db" id="97db" class="graf--h3 graf--leading">Hands-on with Hadoop</h3><h4 name="225a" id="225a" class="graf--h4 graf-after--h3">Hadoop 2.7.2 with…</h4><p name="3c51" id="3c51" class="graf--p graf-after--h4">Yarn is <strong class="markup--strong markup--p-strong">not</strong> the same as just running <strong class="markup--strong markup--p-strong">Hadoop 1.x</strong>. I learnt that the hard way realizing that you shouldn’t (for the 2nd time actually) blindly follow other tutorials out there. The problem is, 95% of them reference v1 and not v2. (MapReduce 2 is also a big change in Hadoop 2.x which causes a few problems for me you’ll see later). Anyways, a couple of days of research later:</p><h4 name="2e72" id="2e72" class="graf--h4 graf-after--p">YARN is…</h4><p name="2779" id="2779" class="graf--p graf-after--h4">Yet Another Resource Negotiator. It’s a layer between HDFS (the file system) and everything else, such as MapReduce and Hive (don’t ask me what Hive is, I haven’t gotten there yet). But needless to say, MapReduce and Hive are analogous to applications which plug into the YARN framework. Plug any app into YARN and it will take care of the resourcing. YARN also allows for non-batch processing apps to be used which is a big deal because Hadoop is all about batch progressing.</p><h4 name="7928" id="7928" class="graf--h4 graf-after--p">Download and install Hadoop with…</h4><p name="8b38" id="8b38" class="graf--p graf-after--h4">these steps below, I went through them pretty easily and quickly although running into issues wasn’t a rare as I thought it would be…</p><pre name="0272" id="0272" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Download and install via terminal</strong></pre><pre name="5a28" id="5a28" class="graf--pre graf-after--pre">1. $cd ~/<br>2. $wget <a href="http://apachemirror.ovidiudan.com/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz" data-href="http://apachemirror.ovidiudan.com/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz" class="markup--anchor markup--pre-anchor" rel="nofollow">http://apachemirror.ovidiudan.com/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz</a><br>3. $sudo mkdir /opt<br>4. $sudo tar -xvzf hadoop-2.7.2.tar.gz -C /opt/<br>5. $cd /opt<br>6. $sudo mv hadoop-2.7.2 hadoop<br>7. $sudo chown -R hduser:hadoop hadoop</pre><p name="1457" id="1457" class="graf--p graf-after--pre">In the above, I’m downloading Hadoop, making a /opt directory (which is apparently a typical folder name to have on Raspberry), expand the tar into /opt, move everything to a better folder name and then give your hduser permission to this new folder. The only issue I came across with these steps was <em class="markup--em markup--p-em">No space left of device,</em> this was due to using the re-formatted SD Card. You’ll need to use the “Expand rootfs / root partition to fill SD Card” option available in rasp-config.</p><p name="c154" id="c154" class="graf--p graf-after--p">With that done, it’s time to setup some system environment variables. I went minimal on this but you can obviously go all out here as I’m pretty sure half of this isn’t needed.</p><pre name="459b" id="459b" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Add to the end of /etc/bash.bashrc the following export lines</strong></pre><pre name="ee10" id="ee10" class="graf--pre graf-after--pre">$sudo nano /etc/bash.bashrc</pre><pre name="3f8c" id="3f8c" class="graf--pre graf-after--pre">export JAVA_HOME=$(readlink -f /usr/bin/java | sed &quot;s:bin/java::&quot;)<br>export HADOOP_HOME=/opt/hadoop<br>export HADOOP_INSTALL=$HADOOP_HOME<br>export YARN_HOME=$HADOOP_HOME<br>export PATH=$PATH:$HADOOP_INSTALL/bin</pre><pre name="5e24" id="5e24" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Apply those changes:</strong> $ source ~/.bashrc</pre><p name="c1d4" id="c1d4" class="graf--p graf-after--pre">Now time for a test, I’m going to exit the terminal (or you can just open a new one) and switch users, then type “hadoop version”.</p><pre name="caff" id="caff" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Test installation, you should get version Hadoop 2.7.2</strong></pre><pre name="3865" id="3865" class="graf--pre graf-after--pre">1. $exit<br>2. $su hduser<br>3. $hadoop version</pre><h4 name="f471" id="f471" class="graf--h4 graf-after--pre">Time to configure Hadoop…</h4><p name="17f2" id="17f2" class="graf--p graf-after--h4">which is both straight forward but also complicated. In the end, it really was just a matter of understanding Hadoop, but also reminding myself that this is only a single-node cluster at the moment with a minimal config setup.</p><pre name="0d28" id="0d28" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Hadoop environment variables, uncomment/update the two export lines</strong></pre><pre name="4be2" id="4be2" class="graf--pre graf-after--pre">$sudo nano /opt/hadoop/etc/hadoop/hadoop-env.sh<br>export JAVA_HOME=$(readlink -f /usr/bin/java | sed &quot;s:bin/java::&quot;)<br>export HADOOP_HEAPSIZE=250</pre><p name="4e66" id="4e66" class="graf--p graf-after--pre">Next up, more configuration files. Paths here are a bit different than in Hadoop 1.x, in v2 you can find these files under <em class="markup--em markup--p-em">/etc/hadoop/</em></p><p name="0065" id="0065" class="graf--p graf-after--p">I went through the config files and updated/added to each one as follows…</p><pre name="9624" id="9624" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">core-site.xml</strong></pre><pre name="62d6" id="62d6" class="graf--pre graf-after--pre">&lt;configuration&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;fs.default.name&lt;/name&gt;<br>    &lt;value&gt;hdfs://node1:9000&lt;/value&gt;<br>  &lt;/property&gt;<br>&lt;/configuration&gt;</pre><p name="fa72" id="fa72" class="graf--p graf-after--pre">…</p><pre name="ed01" id="ed01" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">mapred-site.xml</strong></pre><pre name="d9fa" id="d9fa" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Note:</strong> This is where we&#39;ll tell MapReduce to use the YARN framework. The file doesn&#39;t exist so you&#39;ll need to make a copy from mapred-site.template.xml and edit it</pre><pre name="9cf6" id="9cf6" class="graf--pre graf-after--pre">$cp mapred-site.xml.template mapred-site.xml</pre><pre name="3fde" id="3fde" class="graf--pre graf-after--pre">&lt;configuration&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>    &lt;value&gt;yarn&lt;/value&gt;<br>  &lt;/property&gt;<br>&lt;/configuration&gt;</pre><p name="33ee" id="33ee" class="graf--p graf-after--pre">…</p><pre name="4135" id="4135" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">hdfs-site.xml</strong></pre><pre name="6dbf" id="6dbf" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Note:</strong> The replication property is set to 1, by default it&#39;s 3, with single node we don&#39;t need it to replicate blocks 3 times. NameNode and dataNode paths are self explanatory.</pre><pre name="dba9" id="dba9" class="graf--pre graf-after--pre">&lt;configuration&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;dfs.replication&lt;/name&gt;<br>    &lt;value&gt;1&lt;/value&gt;<br>  &lt;/property&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br>    &lt;value&gt;file:/opt/hadoop/hadoop_data/hdfs/namenode&lt;/value&gt;<br>  &lt;/property&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;dfs.datanode.name.dir&lt;/name&gt;<br>    &lt;value&gt;file:/opt/hadoop/hadoop_data/hdfs/datanode&lt;/value&gt;<br>  &lt;/property&gt;<br>&lt;/configuration&gt;</pre><p name="18fe" id="18fe" class="graf--p graf-after--pre">…</p><pre name="79a5" id="79a5" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">yarn-site.xml</strong></pre><pre name="319b" id="319b" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Note:</strong> Tell NodeManagers there&#39;s an auxiliary service called mapreduce.shuffle to implement and provide the class name in order to implement the service.</pre><pre name="a2b9" id="a2b9" class="graf--pre graf-after--pre">&lt;configuration&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>  &lt;/property&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;<br>    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;<br>  &lt;/property&gt;<br>&lt;/configuration&gt;</pre><p name="f41d" id="f41d" class="graf--p graf-after--pre">Next, I need to create the directories and log folders named above. And remember to give your hduser access, otherwise you’ll end up with a few errors when trying to write (which is exactly what happened to me).</p><pre name="e73b" id="e73b" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Create folders and permissions</strong><br>1. $sudo mkdir -p /opt/hadoop/hadoop_data/hdfs/namenode<br>2. $sudo mkdir -p /opt/hadoop/hadoop_data/hdfs/datanode<br>3. $sudo chown hduser:hadoop /opt/hadoop/hadoop_data/hdfs -R<br>4. $sudo chmod 750 /opt/hadoop/hadoop_data/hdfs</pre><h4 name="52ed" id="52ed" class="graf--h4 graf-after--pre">Formatting and starting up HDFS is…</h4><p name="e21c" id="e21c" class="graf--p graf-after--h4">the last step in the process, prior to actually testing out my creation.</p><pre name="53f8" id="53f8" class="graf--pre graf-after--p">$cd $HADOOP_INSTALL<br>$hdfs namenode -format</pre><pre name="1f9e" id="1f9e" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Output near the bottom:</strong> /opt/hadoop/hadoop_data/hdfs/namenode has been successfully formatted </pre><p name="4179" id="4179" class="graf--p graf-after--pre">Formatting the nameNode gets it prepped for use, just like if you were to format a hard drive or SD Card. Now it’s time to start up the services…</p><pre name="3637" id="3637" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Start, stop and list running services</strong></pre><pre name="2527" id="2527" class="graf--pre graf-after--pre">1. $cd $HADOOP_HOME/sbin<br>2. $./start-dfs.sh<br>3. $./start-yarn.sh<br>4. $jps (to view all running services)<br>(stop-dfs.sh and stop-yarn.sh do what you imagine they would)</pre><p name="8e18" id="8e18" class="graf--p graf-after--pre">Running the jps command should list the services running on the JVM target / host machine. This cmd was very helpful as sometimes services just didn’t start up (you’ll see why later) and it’s good to know sooner rather than later.</p><pre name="ab68" id="ab68" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Run the command and verify you have the below services running</strong></pre><pre name="1d43" id="1d43" class="graf--pre graf-after--pre">$jps<br><br>2169 Jps<br>1232 NameNode<br>1310 SecondaryNameNode<br>1350 DataNode<br>1863 NodeManager<br>1750 ResourceManager</pre><p name="a2ef" id="a2ef" class="graf--p graf-after--pre">Because you’re running on a single node installation, my node1 should act as the nameNode and dataNode (plus with YARN, NodeManager and ResourceManager). You can ignore SecondaryNameNode at this time, it’s only just to take snapshots of the nameNode.</p><h4 name="0f59" id="0f59" class="graf--h4 graf-after--p">Run a test and…</h4><p name="d12c" id="d12c" class="graf--p graf-after--h4">cross your fingers. I now have everything done. Raspberry is set, environment configured, Hadoop installed, user and groups created, Hadoop environment variables set and the Hadoop user has access to all files and folders. The only thing left now is to test my single node installation. And of course Hadoop comes with a bunch of example code I can use as a test. I noticed a “pi” example and figured that should be simple enough of a test for me dive into.</p><pre name="4a3b" id="4a3b" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Run a Hadoop provided example, pi, which calculates the value of pi</strong></pre><pre name="7d93" id="7d93" class="graf--pre graf-after--pre">1. $cd $HADOOP_INSTALL/bin<br>2. $./hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar pi 16 1000</pre><p name="6308" id="6308" class="graf--p graf-after--pre">As an output I should get something like “Estimated value of Pi is 3.1425…”. Things started off so well but I’m writing as it’s running and currently while I wait for my pi outcome, I’m starting to see a number of failures:</p><pre name="7330" id="7330" class="graf--pre graf-after--p">16/03/12 20:40:12 INFO mapred.JobClient: map 44% reduce 15%<br>...<br>INFO mapreduce.Job: Task Id : blah blah, Status : Failed</pre><p name="a5a9" id="a5a9" class="graf--p graf-after--pre">But there is progress — map 44% reduce 15% — which is pretty exciting and that has to count for something, right? Okay, now the whole thing has failed. Time to take a few screen shots and Google some answers, right? Well, I’d like to say that’s what I did, but it’s not. I had a mini frustration meltdown (when did I convince myself this would be easy???) and took a 3 day timeout from Hadoop.</p><p name="8377" id="8377" class="graf--p graf-after--p">Back. Wiped the SD Card. Started over.</p><p name="7bb8" id="7bb8" class="graf--p graf-after--p">I followed my own article notes, making updates as I researched what went wrong. What you see above has already been updated with my notes.</p><p name="f46a" id="f46a" class="graf--p graf-after--p">Time to try a word count, after all, it is the Hello World of Hadoop, isn’t it? (I picked that up from my research). Copy a file to HDFS and run the example mapReduce wordCount on it.</p><pre name="5464" id="5464" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Copy the file,check HDFS for the file then run wordCount on the file</strong></pre><pre name="cbb3" id="cbb3" class="graf--pre graf-after--pre">1. $hdfs dfs -copyFromLocal /opt/hadoop/LICENSE.txt /license.txt<br>2. $hdfs dfs -ls /<br>3. $cd /opt/hadoop/bin<br>4. $./hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /license.txt /license-out.txt</pre><p name="2d82" id="2d82" class="graf--p graf-after--pre">WordCount of the license.txt file worked! No errors and a nice “Job completed successfully” was part of the output near the bottom. Now time to check the actual results.</p><p name="6cdf" id="6cdf" class="graf--p graf-after--p">I first opened the .txt file like a normal person and it was blank (still need to look into why that is) but if you open /part-r-00000, it should have all words in the license.txt file and their number of occurrences — success!</p><pre name="269a" id="269a" class="graf--pre graf-after--p">hdfs dfs -copyToLocal /license-out.txt ~/<br>nano ~/license-out.txt/part-r-00000</pre><p name="feb9" id="feb9" class="graf--p graf-after--pre"><em class="markup--em markup--p-em">Update: that “file” I opened was actually a directory. Hadoop creates a license-out.txt directory with _SUCCESS and part-x-yyyyy files within it.</em></p><p name="8f7b" id="8f7b" class="graf--p graf-after--p"><em class="markup--em markup--p-em">Update: </em><a href="http://stackoverflow.com/a/10666874/1343001" data-href="http://stackoverflow.com/a/10666874/1343001" class="markup--anchor markup--p-anchor" rel="nofollow"><em class="markup--em markup--p-em">What are Success and part-r-xxxxx files in Hadoop</em></a></p><p name="2925" id="2925" class="graf--p graf-after--p">I’m now more intrigued than before as to why the first job failed, 2 out of 3?</p><pre name="a5c6" id="a5c6" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">To delete a directory with non-empty files in it try</strong><br>$hadoop fs -rm -r /license-out.txt</pre><p name="71f7" id="71f7" class="graf--p graf-after--pre">Basically, I’m going to run another wordCount (but on another file), wordMean and rerun the pi test. Moments later…both wordCount and wordMean were successful. However, the first try at pi failed again.</p><pre name="490c" id="490c" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Error trying to run hadoop-mapreduce-examples-2.7.2.jar pi 10 10</strong></pre><pre name="de39" id="de39" class="graf--pre graf-after--pre">16/03/17 22:03:58 INFO mapreduce.Job: Task Id: ..., Status: Failed<br>Exception from container-launch</pre><p name="a657" id="a657" class="graf--p graf-after--pre">I did a little more research and keep seeing a re-occurring theme around setting the classPath for HADOOP_HOME and others. An example of my problem is here on SO for <a href="http://stackoverflow.com/a/25090151/1343001" data-href="http://stackoverflow.com/a/25090151/1343001" class="markup--anchor markup--p-anchor" rel="nofollow"><em class="markup--em markup--p-em">container-launch error</em></a><em class="markup--em markup--p-em"> .</em></p><p name="4909" id="4909" class="graf--p graf-after--p"><em class="markup--em markup--p-em">Update: I’m not pretty sure this was not my problem</em></p><p name="e139" id="e139" class="graf--p graf-after--p">Time for a third attempt, I made a few changes (you already have them if you followed along) and then re-ran the job. I still received some failed jobs but overall this time it all worked.</p><pre name="0e77" id="0e77" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">3nd attempt at calculating Pi</strong><br>Job job_1458..._001 completed successfully<br>...<br>Job Finished in 346.618 seconds<br>Estimated value of Pi is 3.200</pre><p name="db02" id="db02" class="graf--p graf-after--pre">Now I’m a bit sceptical about the results, time for a undo and then a rerun to see if I can replicate the error and/or successful results.</p><pre name="ab97" id="ab97" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">4th, 5th and 6th attempt - approx. 15MB test file</strong></pre><pre name="0742" id="0742" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">test 4 - with $YARN_HOME, etc setup</strong><br>Job Finished in 392.751 seconds<br>Estimated value of Pi is 3.200</pre><pre name="bd04" id="bd04" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">test 5 - without</strong><br>Job Finished in 361.656 seconds<br>File does not exist: hdfs://localhost:9000/user/hduser/QuasiMonteCarlo_.../out/reduce-out</pre><pre name="f614" id="f614" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">test 6 - with $YARN_HOME, etc setup</strong><br>Job Finished in 370.214 seconds<br>Estimated value of Pi is 3.200</pre><pre name="59eb" id="59eb" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Notes from two more tests (7 and 8)</strong><br>It seems that Hadoop is always looking for the /reduce-out directory. The 2nd attempt after a &quot;file does not exist&quot; always results in a successful job...of note, wordCount and wordMean always work on the 1st attempt.</pre><p name="e84b" id="e84b" class="graf--p graf-after--pre">I’m now somewhat satisfied with things, particularly because wordCount and wordMean are always successful. Calculating pi seems to be a hit and miss but I think things are “good enough” for now. Time to move on.</p><h4 name="8ba1" id="8ba1" class="graf--h4 graf-after--p">Hadoop on the browser…</h4><p name="65b7" id="65b7" class="graf--p graf-after--h4">can be found on port 50070 by default and all applications of the cluster can be found at port 8088. I found these two links to be extremely helpful, browsing the logs and file system can be quite simple from the browser.</p><pre name="5562" id="5562" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Default ports for Hadoop and its application cluster</strong></pre><pre name="3612" id="3612" class="graf--pre graf-after--pre">http://node1:50070<br>http://node1:8088</pre><p name="a4ec" id="a4ec" class="graf--p graf-after--pre">That’s it! I put together a single node Hadoop installation on a Raspberry Pi. For the most part it all works, but it’s not a cluster just yet and having a single node version of Hadoop defeats the purpose of using Hadoop. So time to start a cluster.</p><h4 name="26ca" id="26ca" class="graf--h4 graf-after--p">Backup and reuse…</h4><p name="4af4" id="4af4" class="graf--p graf-after--h4">your SD Card to make things easier for setting up the next two RaspberryPi’s. Now, I jumped straight into this and had a little extra manual work in the end, so for you, you should do some prep work first before cloning / backing up your card.</p><p name="4481" id="4481" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Shit happens</strong> — I formatted nameNode and dataNode trying to start fresh, didn’t want the clones to have test data on them. Problem is, when you format the nameNode things stop working. To the best of my knowledge, there’s a clusterID that needs to be sync’d between the nameNode and the dataNodes, what you’ll notice is that after you format the nameNode and try to restart services, the dataNode service will never come up. Here is a thread on SO talking about the error message I received: “<a href="http://stackoverflow.com/questions/26545524/there-are-0-datanodes-running-and-no-nodes-are-excluded-in-this-operation" data-href="http://stackoverflow.com/questions/26545524/there-are-0-datanodes-running-and-no-nodes-are-excluded-in-this-operation" class="markup--anchor markup--p-anchor" rel="nofollow">There are 0 datanode(s) running and no node(s) are excluded in this operation</a>”</p><p name="3fb0" id="3fb0" class="graf--p graf-after--p">The solution I used, because I couldn’t figure out how to update the dataNode clusterID, is to delete the hadoop_data folder, re-create it, add back permissions and start up the services again. Quick and easy solution actually — which took me at least 6hrs before deciding to do it or deciding that I didn’t know how to fix the clusterID.</p><p name="dec0" id="dec0" class="graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Back to cloning </strong>— Delete the hadoop storage directory and then update the hosts file as shown below.</p><pre name="74f2" id="74f2" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Delete hdfs storage, add permissions and repeat for all nodes</strong><br>1. rm -rf /opt/hadoop/hadoop_data<br>2. $sudo mkdir -p /opt/hadoop/hadoop_data/hdfs/namenode (not required for nodes 2 and 3)<br>3. $sudo mkdir -p /opt/hadoop/hadoop_data/hdfs/datanode<br>4. $sudo chown hduser:hadoop /opt/hadoop/hadoop_data/hdfs -R<br>5. $sudo chmod 750 /opt/hadoop/hadoop_data/hdfs</pre><pre name="27ad" id="27ad" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Edit the etc/hosts file<br></strong>$sudo nano /etc/hosts<br>192.168.0.107 node1<br>192.168.0.108 node2<br>192.168.0.109 node3</pre><p name="4285" id="4285" class="graf--p graf-after--pre">Now it’s time to clone the cards. There’s plenty of good instructions out there on cloning SD Cards properly but here’s the one I used, it’s pretty straight forward: <a href="http://computers.tutsplus.com/articles/how-to-clone-raspberry-pi-sd-cards-using-the-command-line-in-os-x--mac-59911" data-href="http://computers.tutsplus.com/articles/how-to-clone-raspberry-pi-sd-cards-using-the-command-line-in-os-x--mac-59911" class="markup--anchor markup--p-anchor" rel="nofollow">how to create a clone/backup of your Raspberry Pi SD Card from a Mac (via terminal)</a>.</p><p name="389d" id="389d" class="graf--p graf-after--p">Once I finished cloning my 2 SD Cards, I plugged everything in and had all 3 on the network. It’s now time to configure things once again, so I logged into each and went through the following steps below…</p><pre name="f465" id="f465" class="graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">Already setup with 3 nodes from part 1 of this series</strong><br>$sudo nano /etc/hosts</pre><pre name="233e" id="233e" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Update ip and hostname for the correct node you&#39;re on</strong><br>$sudo nano /etc/network/interfaces<br>$sudo nano /etc/hostname</pre><pre name="826a" id="826a" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Update node1 slaves file</strong><br>$sudo nano /opt/hadoop/etc/hadoop/slaves<br>add: node1, node2 and node3 each on a separate line</pre><pre name="9f50" id="9f50" class="graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">Test the SSH connection between nodes without requiring passwords. You may need to copy things around.<br></strong>Example - from Node1<br>$su hduser<br>$ssh node2</pre><pre name="f2ee" id="f2ee" class="graf--pre graf-after--pre">If you need to enter the password, you&#39;ll need to copy the key.To copy the key - there&#39;s an easier way but this was my process...</pre><pre name="b255" id="b255" class="graf--pre graf-after--pre">$cat ~/.ssh/id_rsa.pub<br>$ssh node2<br>$nano ~/.ssh/authorized_keys<br>copy+paste from node1 key into node2 authorized_keys file</pre><pre name="35b6" id="35b6" class="graf--pre graf-after--pre">The Authorized_keys file for each node should have 3 keys in it. Make sure you can SSH into all nodes without entering a password:</pre><pre name="8746" id="8746" class="graf--pre graf-after--pre">$su hduser<br>$ssh node1<br>$exit<br>$ssh node2<br>$exit<br>$ssh node3<br>$exit</pre><p name="d42d" id="d42d" class="graf--p graf-after--pre graf--last">Finally, everything is working, at least 1.5hrs later (please don’t ask why this is taking so long, nothing seems to work for me the first time). Now at this point, I think it’s a good time to be thankful that all of my nodes are talking to each other and take a break before starting up the services. Next step (Part 3) getting Hadoop services up and running across the cluster, testing to make sure things work aka data processing is actually distributed across the nodes and then a little optimizing / tuning.</p></div></div></section><section name="c500" class=" section--body section--last"><div class="section-divider layoutSingleColumn"><hr class="section-divider"></div><div class="section-content"><div class="section-inner layoutSingleColumn"><p name="88a6" id="88a6" class="graf--p graf--leading graf--last">Questions? Comments? Let me know. Next up, Hadoop cluster</p></div></div></section>
</section>
<footer><p><a href="https://medium.com/p/b8ccfbe6ba9a">View the original on Medium</a></p></footer></article>
